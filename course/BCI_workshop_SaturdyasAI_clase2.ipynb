{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "qVYVljCVt1Gx",
    "outputId": "bbddc87d-a965-4f5f-a56c-f247b09b622a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "fCRiHqs9tzON",
    "outputId": "c14c13b1-f54c-4557-dbd0-78c6113c3d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Datasets\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My\\ Drive/Datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "mFJoktaVEV3W",
    "outputId": "e7d15346-f1b2-4ff7-84b3-b311361764b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_matrix0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLphIBRxT9gp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tempfile import gettempdir\n",
    "from subprocess import call\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.signal import butter, lfilter, lfilter_zi\n",
    "\n",
    "\n",
    "NOTCH_B, NOTCH_A = butter(4, np.array([55, 65])/(256/2), btype='bandstop')\n",
    "\n",
    "\n",
    "def plot_multichannel(data, params=None):\n",
    "    \"\"\"Create a plot to present multichannel data.\n",
    "    Args:\n",
    "        data (numpy.ndarray):  Multichannel Data [n_samples, n_channels]\n",
    "        params (dict): information about the data acquisition device\n",
    "    TODO Receive labels as arguments\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    n_samples = data.shape[0]\n",
    "    n_channels = data.shape[1]\n",
    "\n",
    "    if params is not None:\n",
    "        fs = params['sampling frequency']\n",
    "        names = params['names of channels']\n",
    "    else:\n",
    "        fs = 1\n",
    "        names = [''] * n_channels\n",
    "\n",
    "    time_vec = np.arange(n_samples) / float(fs)\n",
    "\n",
    "    data = np.fliplr(data)\n",
    "    offset = 0\n",
    "    for i_channel in range(n_channels):\n",
    "        data_ac = data[:, i_channel] - np.mean(data[:, i_channel])\n",
    "        offset = offset + 2 * np.max(np.abs(data_ac))\n",
    "        ax.plot(time_vec, data_ac + offset, label=names[i_channel])\n",
    "\n",
    "    ax.set_xlabel('Time [s]')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "def epoch(data, samples_epoch, samples_overlap=0):\n",
    "    \"\"\"Extract epochs from a time series.\n",
    "    Given a 2D array of the shape [n_samples, n_channels]\n",
    "    Creates a 3D array of the shape [wlength_samples, n_channels, n_epochs]\n",
    "    Args:\n",
    "        data (numpy.ndarray or list of lists): data [n_samples, n_channels]\n",
    "        samples_epoch (int): window length in samples\n",
    "        samples_overlap (int): Overlap between windows in samples\n",
    "    Returns:\n",
    "        (numpy.ndarray): epoched data of shape\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        data = np.array(data)\n",
    "\n",
    "    n_samples, n_channels = data.shape\n",
    "\n",
    "    samples_shift = samples_epoch - samples_overlap\n",
    "\n",
    "    n_epochs =  int(np.floor((n_samples - samples_epoch) / float(samples_shift)) + 1)\n",
    "\n",
    "    # Markers indicate where the epoch starts, and the epoch contains samples_epoch rows\n",
    "    markers = np.asarray(range(0, n_epochs + 1)) * samples_shift\n",
    "    markers = markers.astype(int)\n",
    "\n",
    "    # Divide data in epochs\n",
    "    epochs = np.zeros((samples_epoch, n_channels, n_epochs))\n",
    "\n",
    "    for i in range(0, n_epochs):\n",
    "        epochs[:, :, i] = data[markers[i]:markers[i] + samples_epoch, :]\n",
    "\n",
    "    return epochs\n",
    "\n",
    "\n",
    "def compute_feature_vector(eegdata, fs):\n",
    "    \"\"\"Extract the features from the EEG.\n",
    "    Args:\n",
    "        eegdata (numpy.ndarray): array of dimension [number of samples,\n",
    "                number of channels]\n",
    "        fs (float): sampling frequency of eegdata\n",
    "    Returns:\n",
    "        (numpy.ndarray): feature matrix of shape [number of feature points,\n",
    "            number of different features]\n",
    "    \"\"\"\n",
    "    # 1. Compute the PSD\n",
    "    winSampleLength, nbCh = eegdata.shape\n",
    "\n",
    "    # Apply Hamming window\n",
    "    w = np.hamming(winSampleLength)\n",
    "    dataWinCentered = eegdata - np.mean(eegdata, axis=0)  # Remove offset\n",
    "    dataWinCenteredHam = (dataWinCentered.T*w).T\n",
    "\n",
    "    NFFT = nextpow2(winSampleLength)\n",
    "    Y = np.fft.fft(dataWinCenteredHam, n=NFFT, axis=0)/winSampleLength\n",
    "    PSD = 2*np.abs(Y[0:int(NFFT/2), :])\n",
    "    f = fs/2*np.linspace(0, 1, int(NFFT/2))\n",
    "\n",
    "    # SPECTRAL FEATURES\n",
    "    # Average of band powers\n",
    "    # Delta <4\n",
    "    ind_delta, = np.where(f < 4)\n",
    "    meanDelta = np.mean(PSD[ind_delta, :], axis=0)\n",
    "    # Theta 4-8\n",
    "    ind_theta, = np.where((f >= 4) & (f <= 8))\n",
    "    meanTheta = np.mean(PSD[ind_theta, :], axis=0)\n",
    "    # Alpha 8-12\n",
    "    ind_alpha, = np.where((f >= 8) & (f <= 12))\n",
    "    meanAlpha = np.mean(PSD[ind_alpha, :], axis=0)\n",
    "    # Beta 12-30\n",
    "    ind_beta, = np.where((f >= 12) & (f < 30))\n",
    "    meanBeta = np.mean(PSD[ind_beta, :], axis=0)\n",
    "\n",
    "    feature_vector = np.concatenate((meanDelta, meanTheta, meanAlpha,\n",
    "                                     meanBeta), axis=0)\n",
    "\n",
    "    feature_vector = np.log10(feature_vector)\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def nextpow2(i):\n",
    "    \"\"\"\n",
    "    Find the next power of 2 for number i\n",
    "    \"\"\"\n",
    "    n = 1\n",
    "    while n < i:\n",
    "        n *= 2\n",
    "    return n\n",
    "\n",
    "\n",
    "def compute_feature_matrix(epochs, fs):\n",
    "    \"\"\"\n",
    "    Call compute_feature_vector for each EEG epoch\n",
    "    \"\"\"\n",
    "    n_epochs = epochs.shape[2]\n",
    "\n",
    "    for i_epoch in range(n_epochs):\n",
    "        if i_epoch == 0:\n",
    "            feat = compute_feature_vector(epochs[:, :, i_epoch], fs).T\n",
    "            feature_matrix = np.zeros((n_epochs, feat.shape[0])) # Initialize feature_matrix\n",
    "\n",
    "        feature_matrix[i_epoch, :] = compute_feature_vector(\n",
    "                epochs[:, :, i_epoch], fs).T\n",
    "\n",
    "    return feature_matrix\n",
    "\n",
    "\n",
    "def train_classifier(feature_matrix_0, feature_matrix_1, algorithm='SVM'):\n",
    "    \"\"\"Train a binary classifier.\n",
    "    Train a binary classifier. First perform Z-score normalization, then\n",
    "    fit\n",
    "    Args:\n",
    "        feature_matrix_0 (numpy.ndarray): array of shape (n_samples,\n",
    "            n_features) with examples for Class 0\n",
    "        feature_matrix_0 (numpy.ndarray): array of shape (n_samples,\n",
    "            n_features) with examples for Class 1\n",
    "        alg (str): Type of classifer to use. Currently only SVM is\n",
    "            supported.\n",
    "    Returns:\n",
    "        (sklearn object): trained classifier (scikit object)\n",
    "        (numpy.ndarray): normalization mean\n",
    "        (numpy.ndarray): normalization standard deviation\n",
    "    \"\"\"\n",
    "    # Create vector Y (class labels)\n",
    "    class0 = np.zeros((feature_matrix_0.shape[0], 1))\n",
    "    class1 = np.ones((feature_matrix_1.shape[0], 1))\n",
    "\n",
    "    # Concatenate feature matrices and their respective labels\n",
    "    y = np.concatenate((class0, class1), axis=0)\n",
    "    features_all = np.concatenate((feature_matrix_0, feature_matrix_1),\n",
    "                                  axis=0)\n",
    "\n",
    "    # Normalize features columnwise\n",
    "    mu_ft = np.mean(features_all, axis=0)\n",
    "    std_ft = np.std(features_all, axis=0)\n",
    "\n",
    "    X = (features_all - mu_ft) / std_ft\n",
    "\n",
    "    # Train SVM using default parameters\n",
    "    clf = svm.SVC()\n",
    "    \n",
    "    print('clf_1:',clf)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    pipeline_svm = Pipeline(steps=[(\"estandariz\", StandardScaler()),\n",
    "                                  (\"eseuveeme\", clf)\n",
    "                                  ])\n",
    "    grid_hiperparam_svm = {#\"estandariz__with_mean\": [True],\n",
    "                          #\"estandariz__with_std\": [True],\n",
    "                          \"eseuveeme__C\": [0.96], #np.arange(0.01, 10, 0.05),\n",
    "                          \"eseuveeme__gamma\": [0.005] #np.arange(0.001, 0.1, 0.001)\n",
    "                          }\n",
    "\n",
    "    grid_search_SVM = GridSearchCV(estimator=pipeline_svm,\n",
    "                                  param_grid=grid_hiperparam_svm,\n",
    "                                  cv=2,\n",
    "                                  scoring=\"accuracy\",\n",
    "                                  verbose=3,\n",
    "                                  n_jobs=-1)\n",
    "    \n",
    "    grid_search_SVM.fit(X, y)\n",
    "\n",
    "    best_params = grid_search_SVM.best_params_\n",
    "    best_cv_score = grid_search_SVM.best_score_\n",
    "\n",
    "    clf = grid_search_SVM.best_estimator_\n",
    "\n",
    "    print('clf_2:',clf)\n",
    "\n",
    "    \n",
    "    #clf.fit(X, y)\n",
    "\n",
    "    score = clf.score(X, y.ravel())\n",
    "\n",
    "    # Visualize decision boundary\n",
    "    #plot_classifier_training(clf, X, y, features_to_plot=[0, 1])\n",
    "\n",
    "    return clf, mu_ft, std_ft, score, best_params, best_cv_score\n",
    "\n",
    "\n",
    "def test_classifier(clf, feature_vector, mu_ft, std_ft):\n",
    "    \"\"\"Test the classifier on new data points.\n",
    "    Args:\n",
    "        clf (sklearn object): trained classifier\n",
    "        feature_vector (numpy.ndarray): array of shape (n_samples,\n",
    "            n_features)\n",
    "        mu_ft (numpy.ndarray): normalization mean\n",
    "        std_ft (numpy.ndarray): normalization standard deviation\n",
    "    Returns:\n",
    "        (numpy.ndarray): decision of the classifier on the data points\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize feature_vector\n",
    "    x = (feature_vector - mu_ft) / std_ft\n",
    "    y_hat = clf.predict(x)\n",
    "\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def beep(waveform=(79, 45, 32, 50, 99, 113, 126, 127)):\n",
    "    \"\"\"Play a beep sound.\n",
    "    Cross-platform sound playing with standard library only, no sound\n",
    "    file required.\n",
    "    From https://gist.github.com/juancarlospaco/c295f6965ed056dd08da\n",
    "    \"\"\"\n",
    "    wavefile = os.path.join(gettempdir(), \"beep.wav\")\n",
    "    if not os.path.isfile(wavefile) or not os.access(wavefile, os.R_OK):\n",
    "        with open(wavefile, \"w+\") as wave_file:\n",
    "            for sample in range(0, 300, 1):\n",
    "                for wav in range(0, 8, 1):\n",
    "                    wave_file.write(chr(waveform[wav]))\n",
    "    if sys.platform.startswith(\"linux\"):\n",
    "        return call(\"chrt -i 0 aplay '{fyle}'\".format(fyle=wavefile),\n",
    "                    shell=1)\n",
    "    if sys.platform.startswith(\"darwin\"):\n",
    "        return call(\"afplay '{fyle}'\".format(fyle=wavefile), shell=True)\n",
    "    if sys.platform.startswith(\"win\"):  # FIXME: This is Ugly.\n",
    "        return call(\"start /low /min '{fyle}'\".format(fyle=wavefile),\n",
    "                    shell=1)\n",
    "\n",
    "\n",
    "def get_feature_names(ch_names):\n",
    "    \"\"\"Generate the name of the features.\n",
    "    Args:\n",
    "        ch_names (list): electrode names\n",
    "    Returns:\n",
    "        (list): feature names\n",
    "    \"\"\"\n",
    "    bands = ['delta', 'theta', 'alpha', 'beta']\n",
    "\n",
    "    feat_names = []\n",
    "    for band in bands:\n",
    "        for ch in range(len(ch_names)):\n",
    "            feat_names.append(band + '-' + ch_names[ch])\n",
    "\n",
    "    return feat_names\n",
    "\n",
    "\n",
    "def update_buffer(data_buffer, new_data, notch=False, filter_state=None):\n",
    "    \"\"\"\n",
    "    Concatenates \"new_data\" into \"data_buffer\", and returns an array with\n",
    "    the same size as \"data_buffer\"\n",
    "    \"\"\"\n",
    "    if new_data.ndim == 1:\n",
    "        new_data = new_data.reshape(-1, data_buffer.shape[1])\n",
    "\n",
    "    if notch:\n",
    "        if filter_state is None:\n",
    "            filter_state = np.tile(lfilter_zi(NOTCH_B, NOTCH_A),\n",
    "                                   (data_buffer.shape[1], 1)).T\n",
    "        new_data, filter_state = lfilter(NOTCH_B, NOTCH_A, new_data, axis=0,\n",
    "                                         zi=filter_state)\n",
    "\n",
    "    new_buffer = np.concatenate((data_buffer, new_data), axis=0)\n",
    "    new_buffer = new_buffer[new_data.shape[0]:, :]\n",
    "\n",
    "    return new_buffer, filter_state\n",
    "\n",
    "\n",
    "def get_last_data(data_buffer, newest_samples):\n",
    "    \"\"\"\n",
    "    Obtains from \"buffer_array\" the \"newest samples\" (N rows from the\n",
    "    bottom of the buffer)\n",
    "    \"\"\"\n",
    "    new_buffer = data_buffer[(data_buffer.shape[0] - newest_samples):, :]\n",
    "\n",
    "    return new_buffer\n",
    "\n",
    "\n",
    "class DataPlotter():\n",
    "    \"\"\"\n",
    "    Class for creating and updating a line plot.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nbPoints, chNames, fs=None, title=None):\n",
    "        \"\"\"Initialize the figure.\"\"\"\n",
    "\n",
    "        self.nbPoints = nbPoints\n",
    "        self.chNames = chNames\n",
    "        self.nbCh = len(self.chNames)\n",
    "\n",
    "        self.fs = 1 if fs is None else fs\n",
    "        self.figTitle = '' if title is None else title\n",
    "\n",
    "        data = np.empty((self.nbPoints, 1))*np.nan\n",
    "        self.t = np.arange(data.shape[0])/float(self.fs)\n",
    "\n",
    "        # Create offset parameters for plotting multiple signals\n",
    "        self.yAxisRange = 100\n",
    "        self.chRange = self.yAxisRange/float(self.nbCh)\n",
    "        self.offsets = np.round((np.arange(self.nbCh)+0.5)*(self.chRange))\n",
    "\n",
    "        # Create the figure and axis\n",
    "        plt.ion()\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.ax.set_yticks(self.offsets)\n",
    "        self.ax.set_yticklabels(self.chNames)\n",
    "\n",
    "        # Initialize the figure\n",
    "        self.ax.set_title(self.figTitle)\n",
    "\n",
    "        self.chLinesDict = {}\n",
    "        for i, chName in enumerate(self.chNames):\n",
    "            self.chLinesDict[chName], = self.ax.plot(\n",
    "                    self.t, data+self.offsets[i], label=chName)\n",
    "\n",
    "        self.ax.set_xlabel('Time')\n",
    "        self.ax.set_ylim([0, self.yAxisRange])\n",
    "        self.ax.set_xlim([np.min(self.t), np.max(self.t)])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def update_plot(self, data):\n",
    "        \"\"\" Update the plot \"\"\"\n",
    "\n",
    "        data = data - np.mean(data, axis=0)\n",
    "        std_data = np.std(data, axis=0)\n",
    "        std_data[np.where(std_data == 0)] = 1\n",
    "        data = data/std_data*self.chRange/5.0\n",
    "\n",
    "        for i, chName in enumerate(self.chNames):\n",
    "            self.chLinesDict[chName].set_ydata(data[:, i] + self.offsets[i])\n",
    "\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\" Clear the figure \"\"\"\n",
    "\n",
    "        blankData = np.empty((self.nbPoints, 1))*np.nan\n",
    "\n",
    "        for i, chName in enumerate(self.chNames):\n",
    "            self.chLinesDict[chName].set_ydata(blankData)\n",
    "\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\" Close the figure \"\"\"\n",
    "\n",
    "        plt.close(self.fig)\n",
    "\n",
    "\n",
    "def plot_classifier_training(clf, X, y, features_to_plot=[0, 1]):\n",
    "    \"\"\"Visualize the decision boundary of a classifier.\n",
    "    Args:\n",
    "        clf (sklearn object): trained classifier\n",
    "        X (numpy.ndarray): data to visualize the decision boundary for\n",
    "        y (numpy.ndarray): labels for X\n",
    "    Keyword Args:\n",
    "        features_to_plot (list): indices of the two features to use for\n",
    "            plotting\n",
    "    Inspired from: http://scikit-learn.org/stable/auto_examples/tree/plot_iris.html\n",
    "    \"\"\"\n",
    "\n",
    "    plot_colors = \"bry\"\n",
    "    plot_step = 0.02\n",
    "    n_classes = len(np.unique(y))\n",
    "\n",
    "    x_min = np.min(X[:, 1])-1\n",
    "    x_max = np.max(X[:, 1])+1\n",
    "    y_min = np.min(X[:, 0])-1\n",
    "    y_max = np.max(X[:, 0])+1\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.5)\n",
    "\n",
    "    # Plot the training points\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y == i)\n",
    "        ax.scatter(X[idx, 0], X[idx, 1], c=color, cmap=plt.cm.Paired)\n",
    "\n",
    "    plt.axis('tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "atZeLG1r3a8U",
    "outputId": "62d6c7df-7e6c-4b28-f6ca-0af10de50e64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EEG-ch1</th>\n",
       "      <th>EEG-ch2</th>\n",
       "      <th>EEG-ch3</th>\n",
       "      <th>EEG-ch4</th>\n",
       "      <th>EEG-ch5</th>\n",
       "      <th>EEG-ch6</th>\n",
       "      <th>EEG-ch7</th>\n",
       "      <th>EEG-ch8</th>\n",
       "      <th>EEG-ch9</th>\n",
       "      <th>EEG-ch10</th>\n",
       "      <th>EEG-ch11</th>\n",
       "      <th>EEG-ch12</th>\n",
       "      <th>EEG-ch13</th>\n",
       "      <th>EEG-ch14</th>\n",
       "      <th>EEG-ch15</th>\n",
       "      <th>EEG-ch16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>-25903.627251</td>\n",
       "      <td>-32214.464047</td>\n",
       "      <td>-39001.398484</td>\n",
       "      <td>-29951.552295</td>\n",
       "      <td>-66215.304167</td>\n",
       "      <td>-41883.925861</td>\n",
       "      <td>-82360.475069</td>\n",
       "      <td>-71648.752680</td>\n",
       "      <td>-81000.430757</td>\n",
       "      <td>-69640.352642</td>\n",
       "      <td>-69151.186895</td>\n",
       "      <td>-80950.932566</td>\n",
       "      <td>-71522.074788</td>\n",
       "      <td>-77673.904122</td>\n",
       "      <td>-76176.048475</td>\n",
       "      <td>-44879.393800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>-25905.136045</td>\n",
       "      <td>-32218.126523</td>\n",
       "      <td>-39005.182637</td>\n",
       "      <td>-29954.728063</td>\n",
       "      <td>-66211.288827</td>\n",
       "      <td>-41869.142109</td>\n",
       "      <td>-82357.725169</td>\n",
       "      <td>-71648.582332</td>\n",
       "      <td>-81001.659694</td>\n",
       "      <td>-69635.522067</td>\n",
       "      <td>-69145.285562</td>\n",
       "      <td>-80943.291252</td>\n",
       "      <td>-71517.244213</td>\n",
       "      <td>-77672.431831</td>\n",
       "      <td>-76173.663607</td>\n",
       "      <td>-44880.586235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10237</th>\n",
       "      <td>-25909.151385</td>\n",
       "      <td>-32222.823254</td>\n",
       "      <td>-39004.987954</td>\n",
       "      <td>-29958.135019</td>\n",
       "      <td>-66196.152212</td>\n",
       "      <td>-41832.237485</td>\n",
       "      <td>-82351.446638</td>\n",
       "      <td>-71633.165860</td>\n",
       "      <td>-81000.138732</td>\n",
       "      <td>-69620.093427</td>\n",
       "      <td>-69138.179627</td>\n",
       "      <td>-80935.686442</td>\n",
       "      <td>-71510.077439</td>\n",
       "      <td>-77667.978454</td>\n",
       "      <td>-76169.258901</td>\n",
       "      <td>-44876.692572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>-25907.971119</td>\n",
       "      <td>-32222.312211</td>\n",
       "      <td>-38999.889689</td>\n",
       "      <td>-29959.862832</td>\n",
       "      <td>-66180.285535</td>\n",
       "      <td>-41805.541558</td>\n",
       "      <td>-82342.345201</td>\n",
       "      <td>-71619.854400</td>\n",
       "      <td>-80997.632186</td>\n",
       "      <td>-69610.274096</td>\n",
       "      <td>-69128.993016</td>\n",
       "      <td>-80927.424576</td>\n",
       "      <td>-71504.906168</td>\n",
       "      <td>-77664.547163</td>\n",
       "      <td>-76165.462579</td>\n",
       "      <td>-44873.370790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10239</th>\n",
       "      <td>-25905.902610</td>\n",
       "      <td>-32221.728162</td>\n",
       "      <td>-38999.755845</td>\n",
       "      <td>-29957.696981</td>\n",
       "      <td>-66188.583905</td>\n",
       "      <td>-41823.330731</td>\n",
       "      <td>-82342.722399</td>\n",
       "      <td>-71618.114419</td>\n",
       "      <td>-80999.676359</td>\n",
       "      <td>-69623.646395</td>\n",
       "      <td>-69132.022772</td>\n",
       "      <td>-80930.381326</td>\n",
       "      <td>-71511.415886</td>\n",
       "      <td>-77667.236224</td>\n",
       "      <td>-76168.212479</td>\n",
       "      <td>-44876.035516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            EEG-ch1       EEG-ch2  ...      EEG-ch15      EEG-ch16\n",
       "10235 -25903.627251 -32214.464047  ... -76176.048475 -44879.393800\n",
       "10236 -25905.136045 -32218.126523  ... -76173.663607 -44880.586235\n",
       "10237 -25909.151385 -32222.823254  ... -76169.258901 -44876.692572\n",
       "10238 -25907.971119 -32222.312211  ... -76165.462579 -44873.370790\n",
       "10239 -25905.902610 -32221.728162  ... -76168.212479 -44876.035516\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "'''Loading data'''\n",
    "df_1 = pd.read_csv(\"/content/drive/My Drive/Datasets/Borja/EEG_Borja_OA.csv\")\n",
    "df_1 = df_1.drop(['timestamp', 'sequence', 'battery', 'flags'], axis=1)\n",
    "\n",
    "df_2 = pd.read_csv(\"/content/drive/My Drive/Datasets/Borja/EEG_Borja_OC.csv\")\n",
    "df_2 = df_2.drop(['timestamp', 'sequence', 'battery', 'flags'], axis=1)\n",
    "\n",
    "df_1 = df_1[256:256+5120].reset_index() # 5120 = 20*256 Tomamos 20 segundos de cada clase\n",
    "df_2 = df_2[256*40:256*40+5120].reset_index() \n",
    "\n",
    "df_1 = df_1.drop(['index'], axis=1)\n",
    "df_2 = df_2.drop(['index'], axis=1)\n",
    "\n",
    "df_1_label = df_1.copy()\n",
    "df_2_label = df_2.copy()\n",
    "\n",
    "df_1_label['label'] = 0 # Ojos abiertos\n",
    "df_2_label['label'] = 1 # Ojos cerrados\n",
    "\n",
    "df = pd.concat([df_1,df_2])\n",
    "\n",
    "df.reset_index(inplace = True)\n",
    "df = df.drop(['index'], axis=1)\n",
    "\n",
    "assert len(df_1) == len(df_2)\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUtnWygXBS8U"
   },
   "outputs": [],
   "source": [
    "eeg_data0 = np.array(df_1)\n",
    "eeg_data1 = np.array(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "bfcSe0hY50bn",
    "outputId": "0b1107ec-619e-4461-fefa-898898d7eff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_1: SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "clf_2: Pipeline(memory=None,\n",
      "         steps=[('estandariz',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('eseuveeme',\n",
      "                 SVC(C=0.96, break_ties=False, cache_size=200,\n",
      "                     class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3, gamma=0.005,\n",
      "                     kernel='rbf', max_iter=-1, probability=False,\n",
      "                     random_state=None, shrinking=True, tol=0.001,\n",
      "                     verbose=False))],\n",
      "         verbose=False)\n",
      "Mejores parámetros:  {'eseuveeme__C': 0.96, 'eseuveeme__gamma': 0.005}\n",
      "Mejor score en CV:  0.85\n",
      "85.0% correctly predicted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "    # 16 canales\n",
    "    \n",
    "    \"\"\" 2. SET EXPERIMENTAL PARAMETERS \"\"\"\n",
    "\n",
    "    # Length of the EEG data buffer (in seconds)\n",
    "    # This buffer will hold last n seconds of data and be used for calculations\n",
    "    buffer_length = 7\n",
    "\n",
    "    # Length of the epochs used to compute the FFT (in seconds)\n",
    "    epoch_length = 1\n",
    "\n",
    "    # Amount of overlap between two consecutive epochs (in seconds)\n",
    "    overlap_length = 0.0\n",
    "\n",
    "\n",
    "     # Amount to 'shift' the start of each next consecutive epoch\n",
    "    shift_length = epoch_length - overlap_length\n",
    "\n",
    "    # Index of the channel (electrode) to be used\n",
    "    # 0 = left ear, 1 = left forehead, 2 = right forehead, 3 = right ear\n",
    "    ##index_channel = args.channels\n",
    "    # Name of our channel for plotting purposes\n",
    "    \n",
    "\n",
    "\n",
    "    # Number of seconds to collect training data for (one class)\n",
    "    training_length = 10\n",
    "    fs = 256\n",
    "\n",
    "\n",
    "    '''\n",
    "    dir = './dataframes/16_channels'\n",
    "    files = sorted([dir+'/'+f for f in os.listdir(dir)])\n",
    "\n",
    "    eeg_data0 = np.zeros((46080,16))\n",
    "    eeg_data1 = np.zeros((46080,16))\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for f in files:\n",
    "      array_f = np.load(f)\n",
    "      array_f_0 = array_f[0:2560,:]\n",
    "      array_f_1 = array_f[2560:5120,:]\n",
    "\n",
    "      array_f_0 = array_f_0[:,:] # Seleccionamos el numeor de canales que queremos\n",
    "      array_f_1 = array_f_1[:,:]\n",
    "\n",
    "      eeg_data0[2560*counter:2560*(counter+1),:] = array_f_0\n",
    "      eeg_data1[2560*counter:2560*(counter+1),:] = array_f_1\n",
    "\n",
    "      assert len(eeg_data0) == len(eeg_data1)\n",
    "\n",
    "      counter +=1\n",
    "    '''\n",
    "    # Divide data into epochs\n",
    "    eeg_epochs0 = epoch(eeg_data0, epoch_length * fs,\n",
    "                            overlap_length * fs)\n",
    "    eeg_epochs1 = epoch(eeg_data1, epoch_length * fs,\n",
    "                            overlap_length * fs)\n",
    "    \n",
    "        \n",
    "    \"\"\" 4. COMPUTE FEATURES AND TRAIN CLASSIFIER \"\"\"\n",
    "\n",
    "    feat_matrix0 = compute_feature_matrix(eeg_epochs0, fs)\n",
    "    feat_matrix1 = compute_feature_matrix(eeg_epochs1, fs)\n",
    "\n",
    "    [classifier, mu_ft, std_ft, score, best_params, best_cv_score] = train_classifier(\n",
    "            feat_matrix0, feat_matrix1, 'SVM')\n",
    "\n",
    "    \n",
    "    print('Mejores parámetros: ', best_params)\n",
    "    print('Mejor score en CV: ', best_cv_score)\n",
    "    \n",
    "    print(str(score * 100) + '% correctly predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "MbB4TaK3GQaI",
    "outputId": "be03c225-41d8-49d5-a15f-ba95f1aaef68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_matrix0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "_Tz-rfawF_xs",
    "outputId": "a3fe8cf3-044d-4387-d545-25c66fc8a87a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6a85f29f98>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6gAAAE2CAYAAABssr8yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgAAAAAKgQIVAAAAAFAI/x+nWLTlkVL35QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x2304 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ft0 = pd.DataFrame(feat_matrix0)\n",
    "plt.figure(figsize=(16, 32)) \n",
    "plt.imshow(df_ft0.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "oyQXsnHwG1tK",
    "outputId": "82afb416-81f8-4ec0-ae57-3110b149bf2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6a85f17240>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6gAAAE2CAYAAABssr8yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x2304 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ft1 = pd.DataFrame(feat_matrix1)\n",
    "plt.figure(figsize=(16, 32)) \n",
    "plt.imshow(df_ft1.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-T4W0kS2ICn8"
   },
   "source": [
    "El eje horizontal se divide en las frecuencias:    \n",
    "\n",
    "Delta <4    \n",
    "Theta 4-8    \n",
    "Alpha 8-12    \n",
    "Beta 12-30    \n",
    "\n",
    "Y a su vez cada banda se divide en los 16 canales.    \n",
    "El eje vertival representa el teimpo (20 ecpoch a 1 epoch/s).    \n",
    "En las ondas beta vemos como dos electrodos varían en OA y OC a lo largo del eje temporal. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "4BYMOIx9UUZo",
    "outputId": "41e0b3fa-dd5d-4147-c15d-766f46a12168"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [N [N ...]]\n",
      "ipykernel_launcher.py: error: argument N: invalid int value: '/root/.local/share/jupyter/runtime/kernel-200b0441-5e33-4601-8ab7-befb86fa13d6.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 2: A basic Brain-Computer Interface\n",
    "=============================================\n",
    "Description:\n",
    "In this second exercise, we will learn how to use an automatic algorithm to\n",
    "recognize somebody's mental states from their EEG. We will use a classifier,\n",
    "i.e., an algorithm that, provided some data, learns to recognize patterns,\n",
    "and can then classify similar unseen information.\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import numpy as np  # Module that simplifies computations on matrices\n",
    "import matplotlib.pyplot as plt  # Module used for plotting\n",
    "from pylsl import StreamInlet, resolve_byprop  # Module to receive EEG data\n",
    "\n",
    "#import bci_workshop_tools as BCIw  # Our own functions for the workshop\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \"\"\" 0. PARSE ARGUMENTS \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='BCI Workshop example 2')\n",
    "    parser.add_argument('channels', metavar='N', type=int, nargs='*',\n",
    "        default=[0, 1, 2, 3],\n",
    "        help='channel number to use. If not specified, all the channels are used')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    \"\"\" 1. CONNECT TO EEG STREAM \"\"\"\n",
    "\n",
    "    # Search for active LSL stream\n",
    "    print('Looking for an EEG stream...')\n",
    "    streams = resolve_byprop('type', 'EEG', timeout=2)\n",
    "    if len(streams) == 0:\n",
    "        raise RuntimeError('Can\\'t find EEG stream.')\n",
    "\n",
    "    # Set active EEG stream to inlet and apply time correction\n",
    "    print(\"Start acquiring data\")\n",
    "    inlet = StreamInlet(streams[0], max_chunklen=12)\n",
    "    eeg_time_correction = inlet.time_correction()\n",
    "\n",
    "    # Get the stream info, description, sampling frequency, number of channels\n",
    "    info = inlet.info()\n",
    "    description = info.desc()\n",
    "    fs = int(info.nominal_srate())\n",
    "    n_channels = info.channel_count()\n",
    "\n",
    "    # Get names of all channels\n",
    "    ch = description.child('channels').first_child()\n",
    "    ch_names = [ch.child_value('label')]\n",
    "    for i in range(1, n_channels):\n",
    "        ch = ch.next_sibling()\n",
    "        ch_names.append(ch.child_value('label'))\n",
    "\n",
    "    \"\"\" 2. SET EXPERIMENTAL PARAMETERS \"\"\"\n",
    "\n",
    "    # Length of the EEG data buffer (in seconds)\n",
    "    # This buffer will hold last n seconds of data and be used for calculations\n",
    "    buffer_length = 15\n",
    "\n",
    "    # Length of the epochs used to compute the FFT (in seconds)\n",
    "    epoch_length = 1\n",
    "\n",
    "    # Amount of overlap between two consecutive epochs (in seconds)\n",
    "    overlap_length = 0.8\n",
    "\n",
    "    # Amount to 'shift' the start of each next consecutive epoch\n",
    "    shift_length = epoch_length - overlap_length\n",
    "\n",
    "    # Index of the channel (electrode) to be used\n",
    "    # 0 = left ear, 1 = left forehead, 2 = right forehead, 3 = right ear\n",
    "    index_channel = args.channels\n",
    "    # Name of our channel for plotting purposes\n",
    "    ch_names = [ch_names[i] for i in index_channel]\n",
    "    n_channels = len(index_channel)\n",
    "\n",
    "    # Get names of features\n",
    "    # ex. ['delta - CH1', 'pwr-theta - CH1', 'pwr-alpha - CH1',...]\n",
    "    feature_names = BCIw.get_feature_names(ch_names)\n",
    "\n",
    "    # Number of seconds to collect training data for (one class)\n",
    "    training_length = 20\n",
    "\n",
    "    \"\"\" 3. RECORD TRAINING DATA \"\"\"\n",
    "\n",
    "    # Record data for mental activity 0\n",
    "    BCIw.beep()\n",
    "    eeg_data0, timestamps0 = inlet.pull_chunk(\n",
    "            timeout=training_length+1, max_samples=fs * training_length)\n",
    "    eeg_data0 = np.array(eeg_data0)[:, index_channel]\n",
    "\n",
    "    print('\\nClose your eyes!\\n')\n",
    "\n",
    "    # Record data for mental activity 1\n",
    "    BCIw.beep()  # Beep sound\n",
    "    eeg_data1, timestamps1 = inlet.pull_chunk(\n",
    "            timeout=training_length+1, max_samples=fs * training_length)\n",
    "    eeg_data1 = np.array(eeg_data1)[:, index_channel]\n",
    "\n",
    "    # Divide data into epochs\n",
    "    eeg_epochs0 = BCIw.epoch(eeg_data0, epoch_length * fs,\n",
    "                             overlap_length * fs)\n",
    "    eeg_epochs1 = BCIw.epoch(eeg_data1, epoch_length * fs,\n",
    "                             overlap_length * fs)\n",
    "\n",
    "    \"\"\" 4. COMPUTE FEATURES AND TRAIN CLASSIFIER \"\"\"\n",
    "\n",
    "    feat_matrix0 = BCIw.compute_feature_matrix(eeg_epochs0, fs)\n",
    "    feat_matrix1 = BCIw.compute_feature_matrix(eeg_epochs1, fs)\n",
    "\n",
    "    [classifier, mu_ft, std_ft, score] = BCIw.train_classifier(\n",
    "            feat_matrix0, feat_matrix1, 'SVM')\n",
    "\n",
    "    print(str(score * 100) + '% correctly predicted')\n",
    "\n",
    "    BCIw.beep()\n",
    "\n",
    "    \"\"\" 5. USE THE CLASSIFIER IN REAL-TIME\"\"\"\n",
    "\n",
    "    # Initialize the buffers for storing raw EEG and decisions\n",
    "    eeg_buffer = np.zeros((int(fs * buffer_length), n_channels))\n",
    "    filter_state = None  # for use with the notch filter\n",
    "    decision_buffer = np.zeros((30, 1))\n",
    "\n",
    "    plotter_decision = BCIw.DataPlotter(30, ['Decision'])\n",
    "\n",
    "    # The try/except structure allows to quit the while loop by aborting the\n",
    "    # script with <Ctrl-C>\n",
    "    print('Press Ctrl-C in the console to break the while loop.')\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "\n",
    "            \"\"\" 3.1 ACQUIRE DATA \"\"\"\n",
    "            # Obtain EEG data from the LSL stream\n",
    "            eeg_data, timestamp = inlet.pull_chunk(\n",
    "                    timeout=1, max_samples=int(shift_length * fs))\n",
    "\n",
    "            # Only keep the channel we're interested in\n",
    "            ch_data = np.array(eeg_data)[:, index_channel]\n",
    "\n",
    "            # Update EEG buffer\n",
    "            eeg_buffer, filter_state = BCIw.update_buffer(\n",
    "                    eeg_buffer, ch_data, notch=True,\n",
    "                    filter_state=filter_state)\n",
    "\n",
    "            \"\"\" 3.2 COMPUTE FEATURES AND CLASSIFY \"\"\"\n",
    "            # Get newest samples from the buffer\n",
    "            data_epoch = BCIw.get_last_data(eeg_buffer,\n",
    "                                            epoch_length * fs)\n",
    "\n",
    "            # Compute features\n",
    "            feat_vector = BCIw.compute_feature_vector(data_epoch, fs)\n",
    "            y_hat = BCIw.test_classifier(classifier,\n",
    "                                         feat_vector.reshape(1, -1), mu_ft,\n",
    "                                         std_ft)\n",
    "            print(y_hat)\n",
    "\n",
    "            decision_buffer, _ = BCIw.update_buffer(decision_buffer,\n",
    "                                                    np.reshape(y_hat, (-1, 1)))\n",
    "\n",
    "            \"\"\" 3.3 VISUALIZE THE DECISIONS \"\"\"\n",
    "            plotter_decision.update_plot(decision_buffer)\n",
    "            plt.pause(0.00001)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "\n",
    "        print('Closed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0yxHlYK_fXUk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BCI_workshop_SaturdyasAI_clase2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
